# Jutge AI Model Benchmark Configuration
models:
  - name: "Claude-Sonnet-4"
    provider: "openrouter"
    model_id: "anthropic/claude-sonnet-4"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.0-Flash-001"
    provider: "openrouter"
    model_id: "google/gemini-2.0-flash-001"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.5-Flash"
    provider: "openrouter"
    model_id: "google/gemini-2.5-flash"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "DeepSeek-Chat-V3-0324-Free"
    provider: "openrouter"
    model_id: "deepseek/deepseek-chat-v3-0324:free"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.5-Pro"
    provider: "openrouter"
    model_id: "google/gemini-2.5-pro"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.5-Flash-Preview-05-20"
    provider: "openrouter"
    model_id: "google/gemini-2.5-flash-preview-05-20"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "DeepSeek-Chat-V3-0324"
    provider: "openrouter"
    model_id: "deepseek/deepseek-chat-v3-0324"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Claude-3.7-Sonnet"
    provider: "openrouter"
    model_id: "anthropic/claude-3.7-sonnet"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.5-Flash-Lite-Preview-06-17"
    provider: "openrouter"
    model_id: "google/gemini-2.5-flash-lite-preview-06-17"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "DeepSeek-R1-0528-Free"
    provider: "openrouter"
    model_id: "deepseek/deepseek-r1-0528:free"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "GPT-4o-Mini"
    provider: "openrouter"
    model_id: "openai/gpt-4o-mini"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Mistral-Nemo"
    provider: "openrouter"
    model_id: "mistralai/mistral-nemo"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.5-Flash-Preview"
    provider: "openrouter"
    model_id: "google/gemini-2.5-flash-preview"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "GPT-4.1"
    provider: "openrouter"
    model_id: "openai/gpt-4.1"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "DeepSeek-R1-Free"
    provider: "openrouter"
    model_id: "deepseek/deepseek-r1:free"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "GPT-4.1-Mini"
    provider: "openrouter"
    model_id: "openai/gpt-4.1-mini"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Gemini-2.0-Flash-Lite-001"
    provider: "openrouter"
    model_id: "google/gemini-2.0-flash-lite-001"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Llama-3.3-70B-Instruct"
    provider: "openrouter"
    model_id: "meta-llama/llama-3.3-70b-instruct"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Llama-4-Maverick"
    provider: "openrouter"
    model_id: "meta-llama/llama-4-maverick"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

  - name: "Claude-Opus-4"
    provider: "openrouter"
    model_id: "anthropic/claude-opus-4"
    api_key: null  # Will use OPENROUTER_API_KEY environment variable
    base_url: "https://openrouter.ai/api/v1"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30
    enabled: true

problem_sets:
  hello_world:
    - "P68688_en"  # Hello world!

  basic_algorithms:
    - "P68688_en"   # Hello world!
    - "P62421_en"   # Three words
    - "P57548_en"   # Sum of two integer numbers
    - "P41221_en"   # Sum of three integer numbers
    - "P56118_en"   # Maximum of two integer numbers
    - "P52847_en"   # Maximum of three different integer numbers
    - "P90615_en"   # Maximum of three integer numbers
    - "P15613_en"   # Temperatures
    - "P48107_en"   # Integer division and remainder of two natural numbers

  medium_problems:
    - "P68688_en"   # Hello world!
    - "P62421_en"   # Three words
    - "P57548_en"   # Sum of two integer numbers
    - "P41221_en"   # Sum of three integer numbers
    - "P56118_en"   # Maximum of two integer numbers
    - "P90615_en"   # Maximum of three integer numbers
    - "P92351_en"   # Integer division and remainder of an integer number by a natural number
    - "P98960_en"   # Uppercase and lowercase letters
    - "P42042_en"   # Classification of characters (1)
    - "P90226_en"   # Comparison of words
    - "P92613_en"   # Rounding
    - "P37469_en"   # Time decomposition (1)
    - "P34279_en"   # Add one second
    - "P81629_en"   # Minimum change

  advanced_problems:
    - "P61634_en"   # Leap years
    - "P51126_en"   # Intervals (1)
    - "P56559_en"   # Intervals (2)
    - "P89265_en"   # Intervals (3)
    - "P58294_en"   # The answer
    - "P42042_en"   # Classification of characters (1)
    - "P37469_en"   # Time decomposition (1)
    - "P34279_en"   # Add one second
    - "P92351_en"   # Integer division and remainder of an integer number by a natural number
    - "P98960_en"   # Uppercase and lowercase letters

  one_problem:
    - "P53046_ca"   # De un a ena (2)

  custom_problems:
    - "P98960_en"   # Uppercase and lowercase letters
    - "P51126_en"   # Intervals (1)
    - "P90226_en"   # Comparison of words

# Benchmark settings
max_attempts_per_problem: 1
timeout_per_problem: 300  # 5 minutes
retry_on_failure: true
max_retries: 2
save_detailed_logs: true
output_format: "json"  # "json", "csv", "html"
parallel_strategy: "full"  # "full", "models", "sequential"

# Raw response logging for debugging (helps analyze extraction failures like Gemini 2.5 Pro)
save_raw_responses: true  # Enable to save AI responses for debugging
raw_responses_dir: "results/raw_responses"  # Directory to save raw responses
save_raw_on_failure_only: false  # Set to true to only save when extraction/execution fails 